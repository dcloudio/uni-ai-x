
import { HighLighterOptions, CreateHighLighterRes, ILineTokens, IToken } from '../interface.uts'

export class lineTokens {
	constructor(readonly tokens : IToken[]) { }
}


import { MainActivity } from 'com.dcloud.scopeparser'
import { mapByteOffsetsToCharOffsets, ktToken } from 'com.dcloud.ConvertedToken'


export async function createHighLighter(options : HighLighterOptions) : Promise<CreateHighLighterRes> {

	const languages = options.languages;
	const langMap : Map<string, string> = new Map();
	const grammar = await new MainActivity()
	const handleMap : Map<string, Long> = new Map();

	for (let id in languages) {

		try {
			let jsonStr = JSON.stringify(languages[id])
			langMap.set(id, jsonStr)
		} catch {

		}
	}

	let fns : CreateHighLighterRes = {

		async tokenizeFullText(langId : string, fullCodeText : string) : Promise<ILineTokens[]> {
			let tmlStr = langMap.get(langId)
			let res : ILineTokens[] = []
			// if (tmlStr === null) return res
			if (tmlStr !== null) {
				let handle = grammar.addGrammar(langId, tmlStr)

				const text = fullCodeText.split(/\r\n|\r|\n/);

				for (let i = 0; i < text.length; i++) {
					
					const line = text[i] + "\n";
					const lineTokens : String | null = await grammar.tokenizeLine(handle, langId, line);
					// if (lineTokens === null) return []
					if (lineTokens !== null) {
						
					
					const tokens : IToken[] = []

					let lineTokensJson : ktToken[] | null = JSON.parse<ktToken[]>(lineTokens)


					if (lineTokensJson !== null) {
						let nLineTokens = await mapByteOffsetsToCharOffsets(line, lineTokensJson.toTypedArray())
						nLineTokens.forEach((item : ktToken) => {
							// console.log(item.start)
							const iToken = new IToken(item.start, item.end, item.token.split(" "))
							tokens.push(iToken)

						})
						let nTokens : ILineTokens = new ILineTokens(tokens)
						res.push(nTokens)
					}
					}
				}
				grammar.resetHandle(handle)
			}
			return res
		},
		async tokenizeLine(langId : string, lineText : string, state : any) : Promise<ILineTokens | null> {
			let tmlStr = langMap.get(langId)
			if (tmlStr === null) return null
			let handle : Long | null = handleMap.get(langId)
			if (handle === null) {
				handle = grammar.addGrammar(langId, tmlStr)
				handleMap.set(langId, handle)
			}

			let res : ILineTokens | null = null
			grammar.resetHandle(handle)
			// const start = Date.now()
			const lineTokens : String | null = await grammar.tokenizeLine(handle, langId, lineText);
			// const end = Date.now()
			// console.log('耗时:', end - start)

			if (lineTokens === null) return null

			const tokens : IToken[] = []

			let lineTokensJson : ktToken[] | null = JSON.parse<ktToken[]>(lineTokens)

			if (lineTokensJson !== null) {
				let nLineTokens = await mapByteOffsetsToCharOffsets(lineText, lineTokensJson.toTypedArray())
				nLineTokens.forEach((item : ktToken) => {
					// console.log(item.start)
					const iToken = new IToken(item.start, item.end, item.token.split(" "))
					tokens.push(iToken)

				})
				let nTokens : ILineTokens = new ILineTokens(tokens)
				res = nTokens
			}

			return res
		}

	}

	return fns

}


export class CreateHighLighter {
	uniCodeHighlighter: Promise<CreateHighLighterRes>
	constructor(options : HighLighterOptions) {
		this.uniCodeHighlighter = createHighLighter(options)
	}
	async tokenizeFullText(langId : string, fullCodeText : string) : Promise<ILineTokens[]>{
		return (await this.uniCodeHighlighter).tokenizeFullText(langId, fullCodeText)
	}
	async tokenizeLine(langId : string, lineText : string, state : any) : Promise<ILineTokens | null> {
		return (await this.uniCodeHighlighter).tokenizeLine(langId, lineText, state)
	}
}